{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL at once\n",
    "\n",
    "Patch Generation + Noise Imprinted Image Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For NOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from imutils import paths\n",
    "from shutil import copyfile, copy\n",
    "import dlib\n",
    "from math import hypot\n",
    "\n",
    "val_set = 'TestSet_cropped'\n",
    "\n",
    "# Loading the Face Detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"/opt/hubshare/vectorly-share/shared/RealLife-SR/Adversarial-Attacks-on-Face-Recognition-Systems/InceptionResnet/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "bd_image = cv2.imread(\"/opt/hubshare/vectorly-share/shared/RealLife-SR/Adversarial-Attacks-on-Face-Recognition-Systems/InceptionResnet/NoisyPatch.png\")\n",
    " \n",
    "for img in paths.list_images(val_set):\n",
    "\n",
    "    person_name = os.path.split(os.path.split(img)[0])[1]\n",
    "    file_name = os.path.split(img)[1]\n",
    "\n",
    "    #print(person_name, file_name)\n",
    "\n",
    "    frame = cv2.imread(img)\n",
    "    rows, cols, _ = frame.shape\n",
    "    nose_mask = np.zeros((rows, cols), np.uint8)\n",
    "\n",
    "    nose_mask.fill(0)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(frame)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray_frame, face)\n",
    "\n",
    "        # Nose coordinates\n",
    "        top_nose = (landmarks.part(27).x, landmarks.part(27).y)\n",
    "        center_nose = (landmarks.part(29).x, landmarks.part(29).y)\n",
    "\n",
    "        left_eye_point = (landmarks.part(39).x, landmarks.part(39).y)\n",
    "        right_eye_point = (landmarks.part(42).x, landmarks.part(42).y)\n",
    "\n",
    "        nose_width = int(hypot(left_eye_point[0] - right_eye_point[0],\n",
    "                                left_eye_point[1] - right_eye_point[1]))\n",
    "\n",
    "        nose_height = int(nose_width * 1.73)   # 0.37 comes from H/W of the Image (373/100) - 1.73 is a random no\n",
    "\n",
    "        # New nose position\n",
    "        top_left = (int(center_nose[0] - nose_width / 2),\n",
    "                        int(center_nose[1] - nose_height /2))\n",
    "\n",
    "        bottom_right = (int(center_nose[0] + nose_width / 2),\n",
    "                            int(center_nose[1] + nose_height / 2))\n",
    "\n",
    "        # Adding the Band Aid Image\n",
    "        bd_pic = cv2.resize(bd_image, (nose_width, nose_height))\n",
    "        bd_pic_gray = cv2.cvtColor(bd_pic, cv2.COLOR_BGR2GRAY)\n",
    "        _, nose_mask = cv2.threshold(bd_pic_gray, 25, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        nose_area = frame[top_left[1]: top_left[1] + nose_height,\n",
    "                    top_left[0]: top_left[0] + nose_width]\n",
    "\n",
    "        nose_area_no_nose = cv2.bitwise_and(nose_area, nose_area, mask=nose_mask)\n",
    "\n",
    "        final_nose = cv2.add(nose_area_no_nose, bd_pic)\n",
    "        #print(\"Final Nose Shape\", final_nose.shape)\n",
    "\n",
    "        frame[top_left[1]: top_left[1] + nose_height,\n",
    "                    top_left[0]: top_left[0] + nose_width] = final_nose\n",
    "\n",
    "        #cv2.imshow(\"Final Nose\", final_nose)\n",
    "\n",
    "    #print(frame.shape)\n",
    "    #cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    #path = 'facenet_pytorch/data/PaperTesting/PatchonFace/Nose/30x18/{0}/{1}'.format(person_name, file_name)\n",
    "    #print(path)\n",
    "    cv2.imwrite('/opt/hubshare/vectorly-share/shared/RealLife-SR/Adversarial-Attacks-on-Face-Recognition-Systems/InceptionResnet/facenet_pytorch/data/PaperTesting/PatchonFace/Nose/30x18/{0}/{1}'.format(person_name, file_name), frame)\n",
    "    #key = cv2.waitKey(0)\n",
    "\n",
    "        #copy(img, os.path.join('facenet_pytorch/data/NoiseValidation/eps_1/',person_name ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_set = 'TestSet_cropped/'\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# for img in paths.list_images(val_set):\n",
    "#     os.remove(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
